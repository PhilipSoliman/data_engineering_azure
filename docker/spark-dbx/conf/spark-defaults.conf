spark.master                              spark://spark-master:7077
spark.eventLog.enabled                    true
spark.eventLog.dir                        file:/dbfs/spark-events
spark.history.fs.logDirectory             file:/dbfs/spark-events
spark.sql.warehouse.dir                   file:/dbfs/warehouse
spark.connect.grpc.binding.port           15002
spark.ui.port                             4040
spark.driver.bindAddress                  0.0.0.0

# Lakehouse engines (Delta, Iceberg, Hudi for Spark 4)
spark.sql.extensions                      io.delta.sql.DeltaSparkSessionExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.apache.spark.sql.hudi.HoodieSparkSessionExtension
spark.sql.catalog.spark_catalog           org.apache.spark.sql.delta.catalog.DeltaCatalog

# Hive-style external metastore (schema initialized via schematool)
spark.sql.catalogImplementation           hive
spark.hadoop.javax.jdo.option.ConnectionURL           jdbc:postgresql://metastore-db:5432/hive_metastore
spark.hadoop.javax.jdo.option.ConnectionDriverName    org.postgresql.Driver
spark.hadoop.javax.jdo.option.ConnectionUserName      hive
spark.hadoop.javax.jdo.option.ConnectionPassword      hive
spark.hadoop.datanucleus.schema.validateTables        false
spark.hadoop.datanucleus.schema.validateColumns       false
spark.hadoop.datanucleus.schema.validateConstraints   false

# Dynamic allocation and shuffle tracking
spark.dynamicAllocation.enabled           true
spark.dynamicAllocation.shuffleTracking.enabled true
spark.shuffle.service.enabled             true
spark.executor.cores                      2

# Cloud FS helpers (basic defaults; override credentials via env/secret mounts)
spark.hadoop.fs.s3a.impl                  org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.AbstractFileSystem.s3a.impl org.apache.hadoop.fs.s3a.S3A
spark.hadoop.fs.azure.impl                org.apache.hadoop.fs.azure.NativeAzureFileSystem
spark.hadoop.fs.gs.impl                   com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem

# Sensible defaults
spark.sql.adaptive.enabled                true
spark.sql.parquet.compression.codec       snappy
